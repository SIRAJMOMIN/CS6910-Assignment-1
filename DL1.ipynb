{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe9afab941704155b007b299ca5cc8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4b50bc44b994a9f9dfff2f5a7eb5202",
              "IPY_MODEL_6557c5ddffe74c67ac517cf4f7e850e3"
            ],
            "layout": "IPY_MODEL_54d7899e332d4d628cc6b4b6db689f3b"
          }
        },
        "b4b50bc44b994a9f9dfff2f5a7eb5202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cae4c45cfa24dabb0d57ce474400dc9",
            "placeholder": "​",
            "style": "IPY_MODEL_efbab5358e444a80984286563025f876",
            "value": "0.010 MB of 0.010 MB uploaded\r"
          }
        },
        "6557c5ddffe74c67ac517cf4f7e850e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f50a6442d6d4360adf3cb7527fe1be1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16a7419246da4efd99cbd5a08011ab88",
            "value": 1
          }
        },
        "54d7899e332d4d628cc6b4b6db689f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cae4c45cfa24dabb0d57ce474400dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efbab5358e444a80984286563025f876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f50a6442d6d4360adf3cb7527fe1be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a7419246da4efd99cbd5a08011ab88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "_64xxvypyuE0",
        "outputId": "68935e0b-afcc-45aa-e51b-cce9de81d7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.42.0-py2.py3-none-any.whl (263 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.5/263.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.42 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.42.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240316_095945-n55h02jo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/n55h02jo' target=\"_blank\">smooth-wood-45</a></strong> to <a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201' target=\"_blank\">https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/n55h02jo' target=\"_blank\">https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/n55h02jo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/n55h02jo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7989f503ae90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#initializing my project and entity in wandb\n",
        "#Deep Learning Assignment 1\n",
        "#CS23M064\n",
        "\n",
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.init(project='Deep Learning Assignment 1', entity='CS23M064')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import numpy ,fashion_mnist and load data\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "import numpy as np\n",
        "\n",
        "((x_train,y_train),(x_test,y_test)) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qubvHSpyzHH-",
        "outputId": "ef23e3b9-57d5-44a4-cec0-d8f09890741d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example image from each class\n",
        "\n",
        "images = []\n",
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "for class_label in range(len(classes)):\n",
        "    index = next(i for i, y in enumerate(y_train) if y == class_label)\n",
        "    images.append(wandb.Image(x_train[index], caption=classes[class_label]))\n",
        "\n",
        "wandb.log({\"example image from each class\": images})\n"
      ],
      "metadata": {
        "id": "TSHeOIMYzRAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleLayer:\n",
        "\n",
        "# optimizer and activation functions and initializing Momentum and velocity weights and bias\n",
        "  def __init__(self, idim, nof_nodes, activation='', optimizer='gradient_descent', weight_type='random'):\n",
        "    self.optimizer = self.do_optimizer(optimizer)\n",
        "    self.opt=optimizer\n",
        "    self.activation, self.activationForwardFunction, self.activationBackwardFunction = self.do_activation(activation)\n",
        "\n",
        "    self.weights, self.bias = self.initialize(idim, nof_nodes, activation, weight_type=weight_type)\n",
        "    self.pv_weight, self.pv_bias = np.zeros([nof_nodes, idim]), np.zeros([nof_nodes, 1])\n",
        "    self.pm_weight, self.pm_bias = np.zeros([nof_nodes, idim]), np.zeros([nof_nodes, 1])\n",
        "# initialization of weights and bias to layer with random-normal distribution or xavier distribution\n",
        "  def initialize(self, nof_inputfeatures, nof_nodes,activation,weight_type):\n",
        "    np.random.seed(1)\n",
        "    if weight_type == 'random':\n",
        "      w=np.random.normal(0.0,0.5,size=(nof_nodes, nof_inputfeatures))\n",
        "    else:\n",
        "      x=np.sqrt(nof_nodes)\n",
        "      w=np.random.uniform(-(1/x), (1/x), size=(nof_nodes, nof_inputfeatures))\n",
        "    b = np.ones([nof_nodes, 1])\n",
        "    return w,b\n",
        "# selection of optimizer based on input value\n",
        "  def do_optimizer(self, optimizer):\n",
        "    if optimizer == 'gradient_descent':\n",
        "        return self.gradient_descent\n",
        "    elif optimizer == 'momentum_gradient_descent':\n",
        "        return self.momentum_gradient_descent\n",
        "    elif optimizer == 'rmsprop':\n",
        "        return self.rmsprop\n",
        "    elif optimizer == 'adam':\n",
        "        return self.adam\n",
        "    elif optimizer == 'stochastic_gradient_descent':\n",
        "        return self.stochastic_gradient_descent\n",
        "    elif optimizer == 'nadam':\n",
        "        return self.nadam\n",
        "    elif optimizer == 'nesterov':\n",
        "        return self.nesterov\n",
        "#selection of activation function based on input value\n",
        "  def do_activation(self, activation):\n",
        "    if activation == 'sigmoid':\n",
        "        return activation, self.sigmoid, self.sigmoid_grad\n",
        "    elif activation == 'relu':\n",
        "        return activation, self.relu, self.relu_grad\n",
        "    elif activation == 'tanh':\n",
        "        return activation, self.tanh, self.tanh_grad\n",
        "    else:\n",
        "        return 'softmax', self.softmax, self.softmax_grad\n",
        "\n",
        "#activation functions and their derivatives\n",
        "#sigmoid function\n",
        "  def sigmoid(self, Z):\n",
        "    Z=np.clip(Z,500,-500)\n",
        "    A = 1 / (1 + np.exp(-Z))\n",
        "    return A\n",
        "\n",
        "# derivative of sigmoid function\n",
        "  def sigmoid_grad(self, derivative_A):\n",
        "    e=np.exp(-(self.previous_Z))\n",
        "    s = 1/(1+e)\n",
        "    derivative_Z = derivative_A * s * (1 - s)\n",
        "    return derivative_Z\n",
        "\n",
        " #tanh activation function\n",
        "  def tanh(self,Z):\n",
        "    return np.tanh(Z)\n",
        "# derivative of tanh function\n",
        "  def tanh_grad(self,derivative_A):\n",
        "    s=self.tanh(self.previous_Z)\n",
        "    ss=(s**2)\n",
        "    return derivative_A*(1-ss)\n",
        "#relu activation function\n",
        "  def relu(self,Z):\n",
        "    A= np.maximum(0,Z)\n",
        "    return A\n",
        "# derivative of relu function\n",
        "  def relu_grad(self,derivative_A):\n",
        "    s= np.maximum(0,self.previous_Z)\n",
        "    t = 1.*(s>0)*derivative_A\n",
        "    return t\n",
        "#softmax activation function\n",
        "  def softmax(self,Z):\n",
        "    maxZ=np.max(Z)\n",
        "    eZ=np.exp(Z - maxZ)\n",
        "    A = eZ/eZ.sum(axis=0, keepdims=True)\n",
        "    return A\n",
        "#gradient of softmax function\n",
        "  def softmax_grad(self,derivative_A):\n",
        "    return derivative_A\n",
        "\n",
        "#forward propagation of input vector A\n",
        "  def forward_propagate(self, A):\n",
        "    if self.opt != 'nesterov':\n",
        "      Z= np.dot(self.weights,A) + self.bias\n",
        "    else:\n",
        "      xw=0.9*self.pv_weight\n",
        "      xw=self.weights-xw\n",
        "      xb=0.9*self.pv_bias\n",
        "      xb=self.bias-xb\n",
        "      Z=np.dot(xw, A) + xb\n",
        "    self.previous_A = A\n",
        "    self.previous_Z = Z\n",
        "    A = self.activationForwardFunction(Z)\n",
        "    return A\n",
        "#backward propagation\n",
        "  def backward_propagate(self, derivative_A):\n",
        "    sp=self.previous_A.shape[1]\n",
        "    derivative_Z = self.activationBackwardFunction(derivative_A)\n",
        "    sum_value=np.sum(derivative_Z, axis=1, keepdims=True)\n",
        "    self.derivative_b = 1/sp*sum_value\n",
        "    self.derivative_w = 1 / sp * np.dot(derivative_Z, self.previous_A.T)\n",
        "    return np.dot(self.weights.T, derivative_A)\n",
        "\n",
        "  def predict(self,A):\n",
        "    x=np.dot(self.weights,A)\n",
        "    Z=self.bias + x\n",
        "    A=self.activationForwardFunction(Z)\n",
        "    return A\n",
        "\n",
        "#stochastic gradient descent algorithm for updating weights\n",
        "  def stochastic_gradient_descent(self, derivative_A,learn_rate = 0.001,t = 0,l2_lambda=0,batch_size = 32):\n",
        "    derivative_Z=self.activationBackwardFunction(derivative_A)\n",
        "    a= self.previous_A.shape[1]\n",
        "    previous_derivative_A = np.dot(self.weights.T, derivative_Z)\n",
        "    for i in range(a):\n",
        "      b=derivative_Z[:,i:i+1]\n",
        "      self.derivative_b=1/a*b\n",
        "      self.derivative_w = 1/a*np.dot(b,self.previous_A[:,i:i+1].T)\n",
        "      c=l2_lambda/batch_size\n",
        "      xw=learn_rate*self.derivative_w\n",
        "      self.weights -=xw- learn_rate *c*self.weights\n",
        "      xb=learn_rate * self.derivative_b\n",
        "      self.bias -=xb-c*self.bias\n",
        "    return previous_derivative_A\n",
        "\n",
        "    # rmsprop algorithm for gradient descent\n",
        "  def rmsprop(self, learn_rate,t,l2_lambda=0,batch_size =32, mrate = 0.9):\n",
        "    gws=np.square(self.derivative_w)\n",
        "    gbs = np.square(self.derivative_b)\n",
        "    nmrate=1-mrate\n",
        "    self.pv_weight = mrate * self.pv_weight + nmrate * gws\n",
        "    self.pv_bias = mrate * self.pv_bias + nmrate *gbs\n",
        "    self.pv_bias[self.pv_bias<0] = 1e-9\n",
        "    for i in self.pv_weight:\n",
        "      i[i<0]=1e-9\n",
        "    a= (learn_rate * l2_lambda / batch_size)\n",
        "    self.weights=self.weights-a * self.weights\n",
        "    self.bias= self.bias -a * self.bias\n",
        "    b=np.sqrt(self.pv_bias+(1e-8))\n",
        "    c= learn_rate/b\n",
        "    self.weights = self.weights - c*self.derivative_w\n",
        "    self.bias = self.bias - c*self.derivative_b\n",
        "\n",
        "  def gradient_descent(self, learn_rate,l2_lambda =0,batch_size =32,t=0):\n",
        "    c=l2_lambda/batch_size\n",
        "    self.weights = self.weights - learn_rate * self.derivative_w-learn_rate*c*self.weights\n",
        "    self.bias = self.bias - learn_rate * self.derivative_b-c*self.bias\n",
        "\n",
        " #momentum gradient descent\n",
        "  def momentum_gradient_descent(self, learn_rate,t,l2_lambda=0,batch_size =32, mrate=0.9):\n",
        "    c=l2_lambda/batch_size\n",
        "    self.pm_weight= mrate*self.pm_weight + learn_rate * self.derivative_w+c*self.weights\n",
        "    self.pm_bias= mrate * self.pm_bias+learn_rate*self.derivative_b+c*self.bias\n",
        "    self.weights-=self.pm_weight\n",
        "    self.bias -=self.pm_bias\n",
        "\n",
        "#nesterov algorithm\n",
        "  def nesterov(self,learn_rate,mrate = 0.9,l2_lambda =0,batch_size =32,t = 0):\n",
        "    self.pv_weight = mrate * self.pv_weight + learn_rate * self.derivative_w\n",
        "    self.weights-=self.pv_weight\n",
        "    self.bl = self.bias - mrate * self.pv_bias\n",
        "    self.pv_bias *= mrate\n",
        "\n",
        "#adam algorithm\n",
        "  def adam(self,learn_rate , beta1 = 0.9, beta2 = 0.999,l2_lambda =0,batch_size =32,t=0):\n",
        "    nbeta1=1-beta1;\n",
        "    nbeta2=1-beta2;\n",
        "    self.pm_weight = beta1 * self.pm_weight + nbeta1*self.derivative_w\n",
        "    self.pm_bias = beta1 * self.pm_bias + nbeta1*self.derivative_b\n",
        "    sw=np.square(self.derivative_w)\n",
        "    sb=np.square(self.derivative_b)\n",
        "    self.pv_weight = beta2 * self.pv_weight+ nbeta2*sw\n",
        "    self.pv_bias = beta2 * self.pv_bias + nbeta2*sb\n",
        "    self.pm_weightH = self.pm_weight/nbeta1\n",
        "    self.pm_biasH = self.pm_bias/nbeta1\n",
        "    self.pv_weightH = self.pv_weight/nbeta2\n",
        "    self.pv_biasH = self.pv_bias/nbeta2\n",
        "    rw=np.sqrt(self.pv_weightH+(1e-8))\n",
        "    self.weights = self.weights - learn_rate * np.divide(self.pm_weightH,rw)\n",
        "    rb=np.sqrt(self.pv_biasH+(1e-8))\n",
        "    self.bias = self.bias - learn_rate * np.divide(self.pm_biasH,rb)\n",
        "\n",
        "\n",
        "\n",
        "#nadam algorithm\n",
        "  def nadam(self,learn_rate ,t, beta1 = 0.9, beta2 = 0.999,l2_lambda =0,batch_size =32):\n",
        "    nbeta1=1-beta1\n",
        "    nbeta2=1-beta2\n",
        "    self.pm_weight=beta1*self.pm_weight+nbeta1*self.derivative_w\n",
        "    self.pm_bias=beta1*self.pm_bias+nbeta1*self.derivative_b\n",
        "    sw=np.square(self.derivative_w)\n",
        "    sb=np.square(self.derivative_b)\n",
        "    self.pv_weight=beta2*self.pv_weight+nbeta2*sw\n",
        "    self.pv_bias=beta2*self.pv_bias+nbeta2*sb\n",
        "    self.pm_weightH = (beta1 * self.pm_weight /nbeta1) + self.derivative_w\n",
        "    self.pm_biasH = (beta1 * self.pm_bias /nbeta1) + self.derivative_b\n",
        "    self.pv_weightH = (beta2 * self.pv_weight) / nbeta2\n",
        "    self.pv_biasH = (beta2 * self.pv_bias) / nbeta2\n",
        "    sw=np.sqrt(self.pv_weightH+(1e-8))\n",
        "    aw=np.divide(self.pm_weightH,sw)\n",
        "    sb= np.sqrt(self.pv_biasH+(1e-8))\n",
        "    ab= np.divide(self.pm_biasH,sb)\n",
        "    self.weights -= (learn_rate *aw)\n",
        "    self.bias -= (learn_rate *ab)\n",
        "\n"
      ],
      "metadata": {
        "id": "bAnHoEmnzUg7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class FeedForwardNeuralNetwork:\n",
        "\n",
        "    def __init__(self, layers_size,epochs=5,learn_rate=0.001, l2_lambda = 0,optimizer = 'gradient_descent', activation = 'sigmoid',weight_type = 'random', loss='cross_entropy'):\n",
        "        self.layers=[]\n",
        "        self.layers_size = layers_size\n",
        "        self.epochs = epochs\n",
        "        self.learn_rate = learn_rate\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        self.weight_type = weight_type\n",
        "        self.l2_lambda = l2_lambda\n",
        "        if loss =='mean_square':\n",
        "            self.losscomputation = self.mean_square\n",
        "            self.lossBackwardpass = self.mean_square_grad\n",
        "        elif loss =='cross_entropy':\n",
        "            self.losscomputation = self.cross_entropy\n",
        "            self.lossBackwardpass = self.cross_entropy_grad\n",
        "        else:\n",
        "            print('loss computation is invalid')\n",
        "        self.loss=loss\n",
        "\n",
        "  # addition of  layer to the feedforward neural network\n",
        "    def addingLayer(self, idim=None, nof_nodes=1, activation='', weight_type='random'):\n",
        "        if not self.layers:\n",
        "            if idim is None:\n",
        "              print('Invalid number of layers')\n",
        "        else:\n",
        "            if idim is None:\n",
        "              idim = self.layers[-1].outputDimension()\n",
        "        add_layer = SingleLayer(idim,nof_nodes, activation, optimizer=self.optimizer, weight_type=weight_type)\n",
        "        self.layers.append(add_layer)\n",
        "\n",
        "    # mean_square error\n",
        "    def mean_square(self, Y, A):\n",
        "        l=np.square(Y - A)\n",
        "        b_sum=np.sum(l)\n",
        "        a= Y.shape[1]\n",
        "        c = 1 / a * b_sum\n",
        "        return np.squeeze(c)\n",
        "\n",
        "    # mean_square_grad\n",
        "    def mean_square_grad(self, Y, A):\n",
        "        x=Y-A\n",
        "        dA = -2 * x\n",
        "        return dA\n",
        "\n",
        "\n",
        "    # cross_entropy\n",
        "    def cross_entropy(self, Y, A):\n",
        "        a = Y.shape[1]\n",
        "        b=np.sum(Y*np.log(A))\n",
        "        c = -(1/a)*b\n",
        "        return np.squeeze(c)\n",
        "\n",
        "\n",
        "    # cross_entropy_grad\n",
        "    def cross_entropy_grad(self, Y, A):\n",
        "        dA = A-Y\n",
        "        return dA\n",
        "\n",
        "\n",
        "    # to get loss from predicted values\n",
        "    def cost(self, Y, A):\n",
        "        return self.losscomputation(Y, A)\n",
        "\n",
        "\n",
        "    # Forwarding X through all layers\n",
        "    def forward_propagate(self, X):\n",
        "        result = np.copy(X)\n",
        "        for each_layer in self.layers:\n",
        "            result = each_layer.forward_propagate(result)\n",
        "        return result\n",
        "\n",
        "\n",
        "    # Backward pass Y and A in reverse direction\n",
        "    def backward_propagate(self, Y, A):\n",
        "        derivative_A = self.lossBackwardpass(Y, A)\n",
        "        if self.optimizer != 'stochastic_gradient_descent':\n",
        "            for each_layer in reversed(self.layers):\n",
        "                derivative_A = each_layer.backward_propagate(derivative_A)\n",
        "        elif self.optimizer =='stochastic_gradient_descent':\n",
        "            for each_layer in reversed(self.layers):\n",
        "                derivative_A = each_layer.stochastic_gradient_descent(derivative_A,learn_rate = self.learn_rate)\n",
        "\n",
        "\n",
        "    # Update the weights and calculate gradient descent of all the layers\n",
        "    def update_Weight(self, learn_rate=0.01,l2_lambda =0,batch_size=32,t=0):\n",
        "        for each_layer in self.layers:\n",
        "            each_layer.optimizer(learn_rate,l2_lambda = l2_lambda,batch_size = batch_size,t=0)\n",
        "\n",
        "\n",
        "    # Train data for validation and test data\n",
        "    def fit(self,x_train,y_train,x_test,y_test,batch_size = 32):\n",
        "\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        x,x_value,y,y_value = train_test_split(x_train,y_train,train_size = 0.9, test_size = 0.1, random_state=10)\n",
        "\n",
        "        if self.activation=='relu':\n",
        "          self.weight_type = 'xavier'\n",
        "    #add the layers with activation functions by calling adding layer\n",
        "        l=len(self.layers_size)\n",
        "        for k in range(1,l-1):\n",
        "          self.addingLayer(idim=self.layers_size[k-1], nof_nodes=self.layers_size[k], activation=self.activation, weight_type = self.weight_type)\n",
        "\n",
        "\n",
        "    # softmax activation function for the last l layer\n",
        "        self.addingLayer(idim=self.layers_size[-2], nof_nodes=self.layers_size[-1], activation='softmax', weight_type = self.weight_type)\n",
        "\n",
        "    #one hot encoder\n",
        "        i=len(y)\n",
        "        j=len(set(y))\n",
        "        y_encoder = np.zeros([j,i])\n",
        "        for k in range(y_encoder.shape[1]):\n",
        "          y_encoder[y[k]][k] = 1\n",
        "\n",
        "  #Training  the data through epochs\n",
        "        for i in range(self.epochs):\n",
        "\n",
        "  #avoid gradient vanishing\n",
        "          if self.activation =='relu':\n",
        "            if self.optimizer == 'momentum_gradient_descent'  or self.optimizer == 'nesterov'or self.optimizer == 'rmsprop':\n",
        "              d=self.learn_rate/15\n",
        "              self.learn_rate=d\n",
        "          #Training the data for each batch\n",
        "          for k in range(0,x.shape[0],batch_size):\n",
        "            kbatch=k+batch_size\n",
        "            xbatch = x[k:kbatch]\n",
        "            ybatch = y[k:kbatch]\n",
        "            y_encoderbatch = y_encoder[:,k:kbatch]\n",
        "            xbatch = xbatch.reshape(xbatch.shape[0],xbatch.shape[1]*xbatch.shape[2]).T\n",
        "            mi=np.min(xbatch)\n",
        "            mx=np.max(xbatch)\n",
        "            xbatch = xbatch-mi/mx-mi\n",
        "            #feed forward neural network\n",
        "            if self.optimizer == 'stochastic_gradient_descent':\n",
        "              A = self.forward_propagate(xbatch)\n",
        "              self.backward_propagate(y_encoderbatch,A)\n",
        "            elif self.optimizer != 'stochastic_gradient_descent':\n",
        "              A = self.forward_propagate(xbatch)\n",
        "              self.backward_propagate(y_encoderbatch,A)\n",
        "              self.update_Weight(learn_rate=self.learn_rate,l2_lambda = self.l2_lambda,batch_size=batch_size,t= i+1)\n",
        "\n",
        "          #Predicting the Loss, Accuracy and Predicted labels for Validation data and Test data\n",
        "          validation_loss,validation_acc,_=self.predict(x_value,y_value)\n",
        "          loss,accuracy,y_pred= self.predict(x_test,y_test)\n",
        "\n",
        "          #Displaying The Loss and Accuracy for Validation data and Test data\n",
        "          print(\"After \",i+1,\"iterations:\")\n",
        "          print(\"validation loss;\",validation_loss,\"validation accuracy:\",validation_acc)\n",
        "          print(\"test_loss:\",loss,\"test accuracy:\",accuracy)\n",
        "\n",
        "          #Logging the loss and accuracy values for each epoch in wandb panel\n",
        "          wandb.log({\"val_loss\":validation_loss,\"val_accuracy\":validation_acc,\"loss\":loss,\"accuracy\":accuracy,\"epoch\":i})\n",
        "\n",
        "        return y_pred #returning the probabilistic distributions of each class\n",
        "\n",
        "\n",
        "    #predficting loss and accuracy\n",
        "    def predict(self,x,y):\n",
        "        i=x.shape[0]\n",
        "        j=x.shape[1]*x.shape[2]\n",
        "        A = x.reshape(i,j).T\n",
        "        a=len(set(y))\n",
        "        b=len(y)\n",
        "        y_encoder = np.zeros([a,b])\n",
        "        for k in range(y_encoder.shape[1]):\n",
        "          y_encoder[y[k]][k] = 1\n",
        "\n",
        "        for each_layer in self.layers:\n",
        "            A = each_layer.predict(A)\n",
        "        x=-(y_encoder * np.log(A))\n",
        "        cross_entropy = x.mean() * y_encoder.shape[0]\n",
        "        y_pred = np.argmax(A,axis = 0)\n",
        "        accuracy = (y==y_pred).mean()\n",
        "\n",
        "        return cross_entropy,accuracy,A\n"
      ],
      "metadata": {
        "id": "BQDFRhnNzYU-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#configuration for which Best accuracy is possible (to plot Confusion matrix)\n",
        "best_config={\n",
        "    \"activation\":\"relu\",\n",
        "    \"batch_size\":64,\n",
        "    \"epochs\":10,\n",
        "    \"hidden_size\":128,\n",
        "    \"learn_rate\":1e-03,\n",
        "    \"hidden_layer\":4,\n",
        "    \"optimizer\":\"nadam\",\n",
        "    \"weight_decay\":0.0005,\n",
        "    \"weight_initial\":\"xavier\"\n",
        "}\n",
        "\n",
        "#generating y prediction to plot confusion matrix\n",
        "np.random.seed(1)\n",
        "wandb.init(config = best_config,project = \"Deep Learning Assignment 1\", entity = \"CS23M064\")\n",
        "config = wandb.config\n",
        "model = FeedForwardNeuralNetwork(layers_size = [784]+[config.hidden_size]*config.hidden_layer+[10],epochs = config[\"epochs\"],learn_rate = config.learn_rate,l2_lambda = config.weight_decay,loss='mean_square',activation = config.activation, optimizer = config.optimizer, weight_type=config.weight_initial )\n",
        "y_pred = model.fit(x_train,y_train,x_test,y_test,batch_size=config.batch_size)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "fe9afab941704155b007b299ca5cc8b6",
            "b4b50bc44b994a9f9dfff2f5a7eb5202",
            "6557c5ddffe74c67ac517cf4f7e850e3",
            "54d7899e332d4d628cc6b4b6db689f3b",
            "7cae4c45cfa24dabb0d57ce474400dc9",
            "efbab5358e444a80984286563025f876",
            "6f50a6442d6d4360adf3cb7527fe1be1",
            "16a7419246da4efd99cbd5a08011ab88"
          ]
        },
        "id": "_bH7T6C2vXgs",
        "outputId": "85758894-eb0f-491a-c3f3-30bd2ee82d1a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:zpsfaqmo) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.010 MB of 0.010 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe9afab941704155b007b299ca5cc8b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wobbly-cherry-48</strong> at: <a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/zpsfaqmo' target=\"_blank\">https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/zpsfaqmo</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240316_100908-zpsfaqmo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:zpsfaqmo). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240316_101032-hr0o8t2p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/hr0o8t2p' target=\"_blank\">bumbling-dust-49</a></strong> to <a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201' target=\"_blank\">https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/hr0o8t2p' target=\"_blank\">https://wandb.ai/cs23m064/Deep%20Learning%20Assignment%201/runs/hr0o8t2p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After  1 iterations:\n",
            "validation loss; 0.5392592430587623 validation accuracy: 0.822\n",
            "test_loss: 0.5642389220738744 test accuracy: 0.814\n",
            "After  2 iterations:\n",
            "validation loss; 0.4685713036207842 validation accuracy: 0.848\n",
            "test_loss: 0.4802781311014157 test accuracy: 0.838\n",
            "After  3 iterations:\n",
            "validation loss; 0.45823852047141794 validation accuracy: 0.8441666666666666\n",
            "test_loss: 0.4646956863505003 test accuracy: 0.8458\n",
            "After  4 iterations:\n",
            "validation loss; 0.4258708917399787 validation accuracy: 0.8623333333333333\n",
            "test_loss: 0.43695349056003163 test accuracy: 0.8551\n",
            "After  5 iterations:\n",
            "validation loss; 0.4617460913958684 validation accuracy: 0.8545\n",
            "test_loss: 0.4601159478794751 test accuracy: 0.8532\n",
            "After  6 iterations:\n",
            "validation loss; 0.43626806046264555 validation accuracy: 0.8633333333333333\n",
            "test_loss: 0.4457125731533318 test accuracy: 0.8624\n",
            "After  7 iterations:\n",
            "validation loss; 0.4143090394636495 validation accuracy: 0.8656666666666667\n",
            "test_loss: 0.40629756140484496 test accuracy: 0.867\n",
            "After  8 iterations:\n",
            "validation loss; 0.4150611128128424 validation accuracy: 0.8691666666666666\n",
            "test_loss: 0.41514949584478456 test accuracy: 0.8684\n",
            "After  9 iterations:\n",
            "validation loss; 0.39272831937849007 validation accuracy: 0.8746666666666667\n",
            "test_loss: 0.3974222295489454 test accuracy: 0.8729\n",
            "After  10 iterations:\n",
            "validation loss; 0.3968820051752676 validation accuracy: 0.8695\n",
            "test_loss: 0.4106579635462244 test accuracy: 0.8711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting Confusion matrix\n",
        "\n",
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(probs=y_pred.T,\n",
        "                        y_true=y_test,class_names=classes)})"
      ],
      "metadata": {
        "id": "DFNFVe-9yjRR"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}